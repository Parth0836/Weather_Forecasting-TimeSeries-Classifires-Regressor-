# -*- coding: utf-8 -*-
"""Weather_forecast_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kmdi99hKOYeiw84yCv8QzWbjNVy2jNam
"""

!pip install category_encoders

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import graphviz
import pandas as pd
import category_encoders as ce
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn import metrics
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import export_graphviz, DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import mean_squared_error

 
import os

Bangalore=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Bangalore_1990_2022_BangaloreCity.csv')
Chennai=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Chennai_1990_2022_Madras.csv')
Delhi=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Delhi_NCR_1990_2022_Safdarjung.csv')
Lucknow=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Lucknow_1990_2022.csv')
Mumbai=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Mumbai_1990_2022_Santacruz.csv')
Rajasthan=pd.read_csv('/content/drive/MyDrive/ weather forecasting/Rajasthan_1990_2022_Jodhpur.csv')
Bhubhneshwar=pd.read_csv('/content/drive/MyDrive/ weather forecasting/weather_Bhubhneshwar_1990_2022.csv')
Rourkela=pd.read_csv('/content/drive/MyDrive/ weather forecasting/weather_Rourkela_2021_2022.csv')

Bangalore['city-Name'] = 'Bangalore'
Chennai['city-Name'] = 'Chennai'
Delhi['city-Name'] = 'Delhi'
Lucknow['city-Name'] = 'Lucknow'
Mumbai['city-Name'] = 'Mumbai'
Rajasthan['city-Name'] = 'Rajasthan'
Bhubhneshwar['city-Name'] = 'Bhubhneshwar'
Rourkela['city-Name'] = 'Rourkela'

Lucknow

Mumbai

Rajasthan

Bhubhneshwar.drop(['snow','wdir','wpgt','pres','tsun','wspd'],axis=1,inplace=True)

Bhubhneshwar

Rourkela.drop(['snow','wdir','wpgt','pres','tsun','wspd'],axis=1,inplace=True)

Rourkela

Delhi

Chennai

def clean(df):
    df['prcp'].fillna(method="ffill",inplace=True)
    df['tmin'].fillna(method="ffill",inplace=True)
    df['tmax'].fillna(method="ffill",inplace=True)
    return df

Chennai=clean(Chennai)
Bangalore=clean(Bangalore)
Delhi=clean(Delhi)
Lucknow=clean(Lucknow)
Mumbai=clean(Mumbai)
Rajasthan=clean(Rajasthan)
Bhubhneshwar=clean(Bhubhneshwar)
Rourkela=clean(Rourkela)

Chennai['target']=Chennai.shift(-1)['tmax']
Bangalore['target']=Bangalore.shift(-1)['tmax']
Delhi['target']=Delhi.shift(-1)['tmax']
Lucknow['target']=Lucknow.shift(-1)['tmax']
Mumbai['target']=Mumbai.shift(-1)['tmax']
Rajasthan['target']=Rajasthan.shift(-1)['tmax']
Bhubhneshwar['target']=Bhubhneshwar.shift(-1)['tmax']
Rourkela['target']=Rourkela.shift(-1)['tmax']

Rajasthan.isnull().sum()

frames = [Chennai, Bangalore,Delhi,Lucknow,Mumbai,Rajasthan,Bhubhneshwar,Rourkela]
df = pd.concat(frames)

Rourkela

df.shape

df.isnull().sum()

df.index

df.head()

df.tail()

df.isnull().sum()

df.reset_index()

df['city-Name']=df['city-Name'].map({'Chennai': '0', 'Bangalore': '1','Delhi':'2','Lucknow':'3','Mumbai':'4','Rajasthan':'5','Bhubhneshwar':'6','Rourkela':'7'})

df

df.dtypes

df.set_index('time',inplace=True)

df.sort_values(by='time')

df.index

df.index= pd.to_datetime(df.index)
df.dtypes

df['city-Name']=df['city-Name'].astype(str).astype(int)

df.index.year

df.isnull().sum()

df.head()

df[['tmax','tmin']].plot(figsize=(15,10))

df[['prcp']].plot(figsize=(15,10))

df[['tmax','tmin']].plot(figsize=(15,10))

df

df=df.iloc[:-1,:].copy()
df

df.drop(['tavg'],axis=1,inplace=True)

df.dropna(inplace=True)

df.isnull().sum()

train=df.loc[:'2022-09-03']
test=df.loc['2020-01-01':]

train

test

from sklearn.linear_model import Ridge

reg = Ridge(alpha=.1)
predictors = ["prcp", "tmax", "tmin","city-Name"]

train[predictors]

reg.fit(train[predictors], train["target"])

predictions = reg.predict(test[predictors])

from sklearn.metrics import mean_squared_error

mean_squared_error(test["target"], predictions)

combined = pd.concat([test["target"], pd.Series(predictions, index=test.index)], axis=1)
combined.columns = ["actual", "predictions"]
combined



combined.plot(figsize=(15,10))

data = {
  "prcp": [0 , 0, 0, 0 ,0 ,0,0, 0.01,0,0,0,0,0],
  "tmax": [37,45,50,52,48,45,43,41,40,41,41,37,39],
    "tmin":[27,30,39,45,40,36,41,39,34,36,33,35,32],
    "city-Name":[0 , 1, 5, 0 ,0 ,4,1, 3,0,4,7,2,2]
}

#load data into a DataFrame object:
df = pd.DataFrame(data)
df

predictions1 = reg.predict(df)
predictions1

print("Setup Complete")

chennai = "/content/drive/MyDrive/ weather forecasting/Chennai_1990_2022_Madras.csv"
bangalore = "/content/drive/MyDrive/ weather forecasting/Bangalore_1990_2022_BangaloreCity.csv"
delhi = "/content/drive/MyDrive/ weather forecasting/Delhi_NCR_1990_2022_Safdarjung.csv"
lucknow = "/content/drive/MyDrive/ weather forecasting/Lucknow_1990_2022.csv"
mumbai = "/content/drive/MyDrive/ weather forecasting/Mumbai_1990_2022_Santacruz.csv"
rajasthan = "/content/drive/MyDrive/ weather forecasting/Rajasthan_1990_2022_Jodhpur.csv"
geolocation = "/content/drive/MyDrive/ weather forecasting/Station_GeoLocation_Longitute_Latitude_Elevation_EPSG_4326.csv"

rajasthan_data = pd.read_csv(rajasthan, index_col="time", infer_datetime_format=True)
mumbai_data = pd.read_csv(mumbai, index_col="time", infer_datetime_format=True)


rajasthan_edata = pd.read_csv(rajasthan);
mumbai_edata = pd.read_csv(mumbai);

print("\nSample Data Of rajasthan\n")

print(rajasthan_data.head())  # 5 data

print("\nMissing Values In The DataSet rajasthan\n")


def find_missing(ds):
    mis_val = ds.isnull().sum()

    mis_val_percent = 100 * ds.isnull().sum() / len(ds)

    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)

    mis_val_table_ren_columns = mis_val_table.rename(
        columns={0: 'Missing Values Count', 1: '% of Total Missing Values'})

    mis_val_table_ren_columns = mis_val_table_ren_columns[
        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(
        '% of Total Missing Values', ascending=False).round(1)

    print("\nYour selected dataframe has " + str(ds.shape[1]) + " columns.\n"
                                                                "There are " + str(mis_val_table_ren_columns.shape[0]) +
          " columns that have missing values.")

    return mis_val_table_ren_columns


missing_values_rajasthan = find_missing(rajasthan_data)
print(missing_values_rajasthan)

rajasthan_data_copy = rajasthan_data.copy(deep=True)

print("\n Linear Interpolation Missing Data Filling\n")

rajasthan_data_copy.interpolate(limit_direction="both", inplace=True)
print(rajasthan_data_copy['tmin'][80:100])
rajasthan_data_copy['tavg'] = rajasthan_data_copy['tavg'].fillna(0).astype(int)
rajasthan_data_copy['tmin'] = rajasthan_data_copy['tmin'].fillna(0).astype(int)
rajasthan_data_copy['tmax'] = rajasthan_data_copy['tmax'].fillna(0).astype(int)
rajasthan_data_copy['prcp'] = rajasthan_data_copy['prcp'].fillna(0).astype(int)

print("\nInfo Of rajasthan Data Set\n")

print(rajasthan_data_copy.info())

col_names = ['tavg', 'tmin', 'tmax', 'class']

rajasthan_data_copy.columns = col_names

print("\nrajasthan Data Set\n")

print(rajasthan_data_copy.head())

print("\nrajasthan Data Set Class Label Counts\n")

print(rajasthan_data_copy['class'].value_counts())

rajasthan_data_copy['class'] = pd.cut(round(rajasthan_data_copy['class'], -1), bins=3, labels=["0", "1", "2"])

tavg_bucket = [20, 24, 28, 32, 36]
tmin_bucket = [12, 16, 20, 24, 28, 31]
tmax_bucket = [23, 27, 31, 35, 39, 44]

tavg_labels = ['20-24', '24-28', '28-32', '32-36']
tmin_labels = ['12 to 16', '16-20', '20-24', '24-28', '28-31']
tmax_labels = ['23-27', '27-31', '31-35', '35-39', '39-44']

print(pd.cut(rajasthan_data_copy.tavg, bins=tavg_bucket, labels=tavg_labels, include_lowest=True).value_counts())
print(pd.cut(rajasthan_data_copy.tmin, bins=tmin_bucket, labels=tmin_labels, include_lowest=True).value_counts())
print(pd.cut(rajasthan_data_copy.tmax, bins=tmax_bucket, labels=tmax_labels, include_lowest=True).value_counts())

rajasthan_data_copy['tavg'] = pd.cut(rajasthan_data_copy.tavg, bins=tavg_bucket, labels=tavg_labels, include_lowest=True)
rajasthan_data_copy['tmin'] = pd.cut(rajasthan_data_copy.tmin, bins=tmin_bucket, labels=tmin_labels, include_lowest=True)
rajasthan_data_copy['tmax'] = pd.cut(rajasthan_data_copy.tmax, bins=tmax_bucket, labels=tmax_labels, include_lowest=True)

print(rajasthan_data_copy['tavg'].max())
print(rajasthan_data_copy['tmin'].max())
print(rajasthan_data_copy['tmax'].max())
print(rajasthan_data_copy['tavg'].min())
print(rajasthan_data_copy['tmin'].min())
print(rajasthan_data_copy['tmax'].min())

rajasthan_data_copy.to_csv("chennai_filled.csv")

# Declare feature vector and target variable

X = rajasthan_data_copy.drop(['class'], axis=1)

y = rajasthan_data_copy['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

print("TRAIN DATA SET SIZE AND TEST DATA SET SIZE")
print(X_train.shape, X_test.shape)

encoder = ce.OrdinalEncoder(cols=['tavg', 'tmin', 'tmax'])

X_train = encoder.fit_transform(X_train)

X_test = encoder.transform(X_test)

print(X_train.head())
print(X_test.head())

clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)

# fit the model
clf_gini.fit(X_train, y_train)

plt.figure(figsize=(12, 8))

tree.plot_tree(clf_gini.fit(X_train, y_train))

plt.show()

y_pred_gini = clf_gini.predict(X_test)

print('Model accuracy score with criterion gini index: {0:0.4f}'.format(accuracy_score(y_test, y_pred_gini)))

y_pred_train_gini = clf_gini.predict(X_train)

print('Training-set accuracy score: {0:0.4f}'.format(accuracy_score(y_train, y_pred_train_gini)))

print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))

print("Confusion Matrix")

print(classification_report(y_test, y_pred_gini))

dot_data = tree.export_graphviz(clf_gini,
                                feature_names=X_train.columns,
                                class_names=y_train,
                                filled=True, rounded=True,
                                special_characters=True)

graph = graphviz.Source(dot_data)

graph

clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)

 
clf_en.fit(X_train, y_train)

y_pred_en = clf_en.predict(X_test)

print('Model accuracy score with criterion entropy: {0:0.4f}'.format(accuracy_score(y_test, y_pred_en)))

y_pred_train_en = clf_en.predict(X_train)

print('Training-set accuracy score: {0:0.4f}'.format(accuracy_score(y_train, y_pred_train_en)))

print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))

plt.figure(figsize=(12, 8))

tree.plot_tree(clf_en.fit(X_train, y_train))

plt.show()

print("Confusion Matrix")

print(classification_report(y_test, y_pred_en))

confusion = metrics.confusion_matrix(y_test, y_pred_en)
print(f"Confusion matrix:\n{confusion}")


# Normalizing by the true label counts to get rates
print(f"\nNormalized confusion matrix:")
for row in confusion:
    print(row / row.sum())

dot_data = tree.export_graphviz(clf_en,
                                feature_names=X_train.columns,
                                class_names=y_train,
                                filled=True, rounded=True,
                                special_characters=True)

graph = graphviz.Source(dot_data)

graph

model = KNeighborsClassifier(n_neighbors=13 )

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred_knn = model.predict(X_test)


print("\n\nK-Nearest Neighbor Accuracy Score: ", (accuracy_score(y_test, y_pred)*100), "%")

print("Confusion Matrix")

print(classification_report(y_test, y_pred_en))

confusion = metrics.confusion_matrix(y_test, y_pred)
print(f"Confusion matrix:\n{confusion}")


# Normalizing by the true label counts to get rates
print(f"\nNormalized confusion matrix:")
for row in confusion:
    print(row / row.sum())

from sklearn.metrics import confusion_matrix

y_true = [0, 1, 2, 0, 1, 2, 0, 1, 2]
y_pred = [0, 1, 1, 0, 2, 2, 0, 1, 2]
cm = confusion_matrix(y_true, y_pred)

cm_df = pd.DataFrame(cm, 
            columns = ['Predicted 0', 'Predicted 1', 'Predicted 2'],
            index = ['Actual 0', 'Actual 1', 'Actual 2'])

def confusion_metrics(conf_matrix):
    TP = conf_matrix[1][1]
    TN = conf_matrix[0][0]
    FP = conf_matrix[0][1]
    FN = conf_matrix[1][0]
    print('True Positives:', TP)
    print('True Negatives:', TN)
    print('False Positives:', FP)
    print('False Negatives:', FN)
    
    #accuracy
    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))
    
    #mis-classification error rate
    conf_misclassification = 1- conf_accuracy
    
    #sensitivity
    conf_sensitivity = (TP / float(TP + FN))
    #specificity
    conf_specificity = (TN / float(TN + FP))
    
    #precision
    conf_precision = (TP / float(TP + FP))
    # calculate f_1 score
    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))
    print('-'*50)
    print(f'Accuracy: {round(conf_accuracy,2)}') 
    print(f'Mis-Classification: {round(conf_misclassification,2)}') 
    print(f'Sensitivity: {round(conf_sensitivity,2)}') 
    print(f'Specificity: {round(conf_specificity,2)}') 
    print(f'Precision: {round(conf_precision,2)}')
    print(f'f_1 Score: {round(conf_f1,2)}')
    
confusion_metrics(cm)

models = []
models.append(('Logistic Regression', LogisticRegression()))
models.append(('Naive Bayes', GaussianNB()))
models.append(('Decision Tree (CART)',DecisionTreeClassifier(criterion='gini')))
models.append(('Decision Tree (ENTROPY)',DecisionTreeClassifier(criterion='entropy')))
models.append(('K-NN', KNeighborsClassifier()))
models.append(('RandomForestClassifier', RandomForestClassifier()))


for name, model in models:
    model = model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    from sklearn import metrics

    print("%s -> ACC: %%%.2f" % (name,metrics.accuracy_score(y_test, y_pred)*100))

clf = RandomForestClassifier(n_estimators=100)

# Training the model on the training dataset
# fit function is used to train the model using the training sets as parameters
clf.fit(X_train, y_train)

# performing predictions on the test dataset
y_pred = clf.predict(X_test)

print()

# using metrics module for accuracy calculation
print("ACCURACY OF THE MODEL: ", metrics.accuracy_score(y_test, y_pred))

print("Confusion Matrix")

print(classification_report(y_test, y_pred))

models = []
models.append(('Logistic Regression', LogisticRegression()))
models.append(('Naive Bayes', GaussianNB()))
models.append(('Decision Tree (CART)',DecisionTreeClassifier(criterion='gini')))
models.append(('Decision Tree (ENTROPY)',DecisionTreeClassifier(criterion='entropy')))
models.append(('K-NN', KNeighborsClassifier()))
models.append(('RandomForestClassifier', RandomForestClassifier()))


for name, model in models:
    model = model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    from sklearn import metrics

    print("\n",name)
    
    print()
    
    print("\n%s -> ACC: %%%.2f" % (name, metrics.accuracy_score(y_test, y_pred)*100))
    
    print("\nConfusion Matrix")

    print(classification_report(y_test, y_pred))
    
    print("\nCLASSIFIER MEASURES FOR %s\n" % (name))
    
    cm = metrics.confusion_matrix(y_test, y_pred)
    confusion_metrics(cm)

import pandas as pd
from sklearn.tree import DecisionTreeRegressor

# Load the Rajasthan weather dataset
rajasthan = pd.read_csv("/content/drive/MyDrive/ weather forecasting/Rajasthan_1990_2022_Jodhpur.csv", index_col="time", infer_datetime_format=True)

# Fill missing data using linear interpolation
rajasthan = rajasthan.interpolate(limit_direction="both")

# Convert date strings to datetime objects
rajasthan.index = pd.to_datetime(rajasthan.index)

# Define a function to predict the weather conditions for a given date
def predict_weather(date):
    # Create a new DataFrame with the weather data for the given date
    new_data = pd.DataFrame({"tavg": [0], "tmin": [0], "tmax": [0], "prcp": [0]}, index=[date])

    # Concatenate the new data with the existing weather data
    data = pd.concat([rajasthan, new_data])

    # Create a new column with the day of year
    data["day"] = data.index.dayofyear

    # Split the data into training and testing sets
    train_data = data.loc[data.index.year < date.year]
    test_data = data.loc[data.index.year == date.year]

    # Fit a decision tree regressor to the training data
    model = DecisionTreeRegressor(random_state=0)
    X_train = train_data["day"].values.reshape(-1, 1)
    y_train = train_data[["tavg", "tmin", "tmax", "prcp"]].values
    model.fit(X_train, y_train)

    # Use the model to predict the weather for the given date
    X_test = test_data["day"].values.reshape(-1, 1)
    y_pred = model.predict(X_test)

    # Extract the predicted weather conditions from the model output
    tavg_pred = int(y_pred[0][0])
    tmin_pred = int(y_pred[0][1])
    tmax_pred = int(y_pred[0][2])
    prcp_pred = int(y_pred[0][3])
    
    # Determine whether it will rain or not based on the predicted precipitation
    will_rain = False
    if prcp_pred > 0:
        will_rain = True

    # Print the predicted weather conditions
    print("Predicted weather conditions for {}: ".format(date))
    print("Average temperature: {}°C".format(tavg_pred))
    print("Minimum temperature: {}°C".format(tmin_pred))
    print("Maximum temperature: {}°C".format(tmax_pred))
    print("Precipitation: {} mm".format(prcp_pred))
    print("Will it rain? {}".format("Yes" if will_rain else "No"))
    
# Prompt the user to input a date
date_str = input("Enter a date (YYYY-MM-DD format): ")
date = pd.to_datetime(date_str)

# Call the predict_weather function with the user input date
predict_weather(date)

import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA

# Load the historical weather data
df = pd.read_csv('/content/drive/MyDrive/ weather forecasting/Rajasthan_1990_2022_Jodhpur.csv')

df['time'] = pd.to_datetime(df['time'])
df.set_index('time', inplace=True)
temperature = df['tmax']

model = ARIMA(temperature, order=(1,1,1))
model_fit = model.fit()

forecast = model_fit.forecast(steps=24)

plt.plot(temperature, label='Historical Data')
plt.plot(forecast, label='Forecast')
plt.legend()
plt.show()